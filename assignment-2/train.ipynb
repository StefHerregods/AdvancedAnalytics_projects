{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training image classifier\n",
    "## Normal classifier\n",
    "First, we perform transfer learning on ResNet50v2 with Keras to classify images on the labels listed in `'cuisines_1'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.applications import ResNet50V2\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load dataframe\n",
    "df = pd.read_csv('labels.csv')\n",
    "\n",
    "# Change 'image_id' to string and add '.jpg' to the end\n",
    "df['image_id'] = df['image_id'].astype(str) + '.jpg'\n",
    "\n",
    "# Split dataframe into train and test\n",
    "train_df = df.sample(frac=0.8, random_state=0)\n",
    "test_df = df.drop(train_df.index)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess image data\n",
    "First we preprocess the image data. For the image augmentation, we rescale the images by 1/255, apply a shear range of 0.2, zoom range of 0.2, and horizontal flip. This is done for both train and test data.\n",
    "Next, we create batches of augmented images of size 32. `class_mode` is set to `categorical` since we have multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77074 validated image filenames belonging to 43 classes.\n",
      "Found 19268 validated image filenames belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data augmentation instance for train set with ImageDataGenerator\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Create batches of augmented images from trainset\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='./images',\n",
    "    x_col='image_id',\n",
    "    y_col='cuisines_1',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create data augmentation instance for test set with ImageDataGenerator\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create batches of augmented images from testset\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='./images',\n",
    "    x_col='image_id',\n",
    "    y_col='cuisines_1',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16, #32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model\n",
    "Load ResNet50v2 model with pretrained ImageNet weights and add a few new layers to finetune with our dataset. Reduce dimensions of the base model with a global average pooling layer and then add a fully connected layer with 1024 units and ReLU activation. Then create the final layer with the number of classes that is uses softmax activation to make classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50V2 model\n",
    "base_model = ResNet50V2(include_top=False, weights='imagenet')\n",
    "\n",
    "# Add new layers on top of ResNet50V2\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "# Define new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the layers in the base model so they don't get overwritten, and then compile the model with Adam optimizer and categorical crossentropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Freeze each layer in the model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 667/2409 [=======>......................] - ETA: 10:30 - loss: 3.3639 - accuracy: 0.2509"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x00000161A10EAE30>\nTraceback (most recent call last):\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 423, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\PIL\\Image.py\", line 3298, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x00000161A10EAE30>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) UNKNOWN:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x00000161A10EAE30>\nTraceback (most recent call last):\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 423, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\PIL\\Image.py\", line 3298, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x00000161A10EAE30>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_19145]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      3\u001b[0m     train_generator,\n\u001b[0;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     validation_data\u001b[39m=\u001b[39;49mtest_generator\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x00000161A10EAE30>\nTraceback (most recent call last):\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 423, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\PIL\\Image.py\", line 3298, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x00000161A10EAE30>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) UNKNOWN:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x00000161A10EAE30>\nTraceback (most recent call last):\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 423, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"c:\\Users\\amarm\\Documents\\GitHub\\AdvancedAnalytics_projects\\assignment-2\\.virtenv2\\lib\\site-packages\\PIL\\Image.py\", line 3298, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x00000161A10EAE30>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_19145]"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=2,\n",
    "    validation_data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('resnet50v2_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "model.save_weights('resnet50v2_weights.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel Classifier\n",
    "Next, we will attempt to train a multilabel classifier that includes all the labels in both `'cuisines_1'` and `'cuisines_2'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.146:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.146:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x25e55c91070>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.functions import regexp_replace, lower\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF\n",
    "from pyspark.sql.functions import regexp_replace, lower\n",
    "import os\n",
    "from pyspark.ml.feature import CountVectorizerModel, IDFModel\n",
    "from pyspark.ml.classification import LogisticRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['models_loaded'] = False\n",
    "globals()['my_model'] = None\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.functions import regexp_replace, lower\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF\n",
    "\n",
    "\n",
    "\n",
    "# Toy predict function that returns a random probability. Normally you'd use your loaded globals()['my_model'] here\n",
    "#def predict(df):\n",
    "#    lr_model = LogisticRegressionModel.load('lr_model')\n",
    "#    prediction = lr_model.transform(df)\n",
    "#    return prediction\n",
    "\n",
    "#predict_udf = udf(predict, StringType())\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(df, column):\n",
    "    df = df.withColumn('review_text_cleaned', lower(regexp_replace(column, '[^\\\\sa-zA-Z0-9]', '')))\n",
    "    df = df.na.fill('null')\n",
    "\n",
    "    # Tokenize the review_text_cleaned column\n",
    "    tokenizer = Tokenizer(inputCol='review_text_cleaned', outputCol='words')\n",
    "    df_tokenized = tokenizer.transform(df)\n",
    "\n",
    "    # Term frequency\n",
    "    #loaded_cv_model = PipelineModel.load('cv_model')\n",
    "    loaded_cv_model = CountVectorizerModel.load('cv_model')\n",
    "    featurizedData = loaded_cv_model.transform(df_tokenized)\n",
    "\n",
    "    # Compute IDF vectors\n",
    "    idfModel = IDFModel.load('idf_model')\n",
    "    rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "    return rescaledData\n",
    "\n",
    "\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    \n",
    "    \n",
    "    df = preprocess(df, 'review_text')\n",
    "    \n",
    "    # Utilize our predict function\n",
    "    #df_withpreds = df.withColumn(\"pred\", predict_udf(\n",
    "    #    struct([df[x] for x in df.columns])\n",
    "    #))\n",
    "    #df_withpreds.show()\n",
    "    \n",
    "    # Normally, you wouldn't use a UDF (User Defined Function) Python function to predict as we did here (you can)\n",
    "    # but an MLlib model you've built and saved with Spark\n",
    "    # In this case, you need to prevent loading your model in every call to \"process\" as follows:\n",
    "    \n",
    "    # Load in the model if not yet loaded:\n",
    "    if not globals()['models_loaded']:\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = LogisticRegressionModel.load('lr_model') # Replace '***' with:    [...].load('my_logistic_regression')\n",
    "        globals()['models_loaded'] = True\n",
    "        \n",
    "    # And then predict using the loaded model (uncomment below):\n",
    "    \n",
    "    df_result = globals()['my_model'].transform(df)\n",
    "    df_result.select('app_id','label','review_id','review_text','probability','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2023-05-25 14:23:00 =========\n",
      "+-------+-----+---------+--------------------+-----------+----------+\n",
      "| app_id|label|review_id|         review_text|probability|prediction|\n",
      "+-------+-----+---------+--------------------+-----------+----------+\n",
      "|2348650|    1|138954943|The game has a we...|  [0.0,1.0]|       1.0|\n",
      "|1062810|    1|138953891|Purchased the gam...|  [1.0,0.0]|       0.0|\n",
      "|1062810|    1|138953878|This game is fant...|  [0.0,1.0]|       1.0|\n",
      "+-------+-----+---------+--------------------+-----------+----------+\n",
      "\n",
      "========= 2023-05-25 14:23:10 =========\n",
      "+-------+-----+---------+--------------------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|         probability|prediction|\n",
      "+-------+-----+---------+--------------------+--------------------+----------+\n",
      "|2141910|    1|138954284|Glad to finally h...|[1.35689366671035...|       1.0|\n",
      "|2423650|    1|138954520|Simple game gotte...|[5.86676168327464...|       1.0|\n",
      "+-------+-----+---------+--------------------+--------------------+----------+\n",
      "\n",
      "========= 2023-05-25 14:23:20 =========\n",
      "+-------+-----+---------+--------------------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|         probability|prediction|\n",
      "+-------+-----+---------+--------------------+--------------------+----------+\n",
      "|1649010|    1|138955080|My Asthma is a co...|[0.99999999999999...|       0.0|\n",
      "|1649010|    1|138954353|Great game, I hav...|           [0.0,1.0]|       1.0|\n",
      "|1649010|    0|138953756|Are you playing w...|[4.75799012225840...|       1.0|\n",
      "+-------+-----+---------+--------------------+--------------------+----------+\n",
      "\n",
      "========= 2023-05-25 14:23:30 =========\n",
      "+-------+-----+---------+--------------------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|         probability|prediction|\n",
      "+-------+-----+---------+--------------------+--------------------+----------+\n",
      "|1607680|    1|138954342|I've fallen many ...|           [0.0,1.0]|       1.0|\n",
      "|1607680|    1|138953798|Gem gud. the wind...|[8.67636754788134...|       1.0|\n",
      "+-------+-----+---------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
